{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment: Authorship Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorship attribution is a type of text classification problem.  Instead of categorizing text by _topic_, as you did in the disease text classification problem, the objective is to classify the text by _author_.  \n",
    "\n",
    "The inherent assumption in trying to solve a problem like this is that there is *some difference between the styles* of the authors in question, *which can be discerned by a model*.  Is that the case for BERT et al?  Is a language model able to \"understand\" written style? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[The Problem](#The-Problem)<br>\n",
    "[Scoring](#Scoring)<br>\n",
    "[Step 1: Prepare the Data](#Step-1:-Prepare-the-Data)<br>\n",
    "[Step 2: Prepare the Model Configuration](#Step-2:-Prepare-the-Model-Configuration)<br>\n",
    "[Step 3: Prepare the Trainer Configuration](#Step-3:-Prepare-the-Trainer-Configuration)<br>\n",
    "[Step 4: Train](#Step-4:-Train)<br>\n",
    "[Step 5: Infer](#Step-5:-Infer)<br>\n",
    "[Step 6: Submit You Assessment](#Step-6:-Submit-You-Assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The Problem\n",
    "### The Federalist Papers - History Mystery!\n",
    "\n",
    "The [Federalist Papers](https://en.wikipedia.org/wiki/The_Federalist_Papers) are a set of essays written between 1787 and 1788 by [Alexander Hamilton](https://en.wikipedia.org/wiki/Alexander_Hamilton), [James Madison](https://en.wikipedia.org/wiki/James_Madison) and [John Jay](https://en.wikipedia.org/wiki/John_Jay).  Initially published under the pseudonym 'Publius', their intent was to encourage the ratification of the then-new Constitution of the United States of America.  In later years, a list emerged where the author of each one of the 85 papers was identified.  Nevertheless, for a subset of these papers the author is still in question.  The problem of the Federalist Papers authorship attribution has been a subject of much research in statistical NLP in the past.   Now you will try to solve this question with your own BERT-based project model.\n",
    "<img style=\"float: right;\" src=\"images/HandM.png\" width=400>\n",
    "                                                                                                           \n",
    "In concrete terms, the problem is identifying, for each one of the disputed papers, whether Alexander Hamilton or James Madison are the authors.  For this exercise, you can assume that each paper has a single author, i.e., that no collaboration took place (though *that* is not 100% certain!), and that each author has a well-defined writing style that is displayed across all the identified papers. \n",
    "\n",
    "### Your Project\n",
    "You are provided with labeled `train.tsv` and `dev.tsv` datasets for the project.  There are 10 test sets, one for each of the disputed papers.  All datasets are contained in the `data/federalist_papers_HM` directory.  \n",
    "\n",
    "Each \"sentence\" is actually a group of sentences of approximately 256 words.  The labels are '0' for HAMILTON and '1' for MADISON.  There are more papers by Hamilton in the example files than by Madison.  The validation set has been created with approximately the same distribution of the two labels as in the training set.\n",
    "\n",
    "Your task is to build neural networks using NeMo, as you did in Lab 2.  You'll train your model and test it.  Then you'll use provided collation code to see what answers your model gives to the \"history mystery\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scoring\n",
    "You will be assessed on your ability to set up and train a model for the project, rather than the final result.  This coding assessment is worth 70 points, divided as follows:\n",
    "\n",
    "### Rubric\n",
    "\n",
    "| Step                                 | Graded                                                    | FIXMEs?  | Points |\n",
    "|--------------------------------------|-----------------------------------------------------------|----------|--------|\n",
    "| 1. Prepare the Project               | Fix data format (correct format)                          |  2       | 10     |\n",
    "| 2. Prepare the Model Configuration   | Set model parameters for override                         |  3       | 15     |\n",
    "| 3. Prepare the Trainer Configuration | Set trainer parameters for override                       |  3       | 15     |\n",
    "| 4. Train                             | Run the Trainer (training logs indicate training correct) |  4       | 20      |\n",
    "| 5. Infer                             | Run Inference (results indicate working project)          |  0       | 10     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you are very capable at this point of building the project without any help at all, some scaffolding is provided, including specific names for variables.  This is for the benefit of the autograder, so please use these constructs for your assessment.  Also, this assessment tests the use of the command line method using the `text_classification_with_bert.py` script and configuration file overrides. You are free to change parameters such as model name, sequence length, batch size, learning rate, number of epochs, and so on to improve your model as you see fit.\n",
    "\n",
    "Once you are confident that you've built a reliable model, follow the instructions for submission at the end of the notebook.\n",
    "\n",
    "### Resources and Hints\n",
    "* **Example code:**<br>\n",
    "In the file browser at your left, you'll find the `lab2_reference_notebooks` directory.  This contains solution notebooks from Lab 2 for text classification and NER to use as examples.\n",
    "* **Language model (PRETRAINED_MODEL_NAME):**<br>\n",
    "You may find it useful to try different language models to better discern style.  Specifically, it may be that capitalization is important, which would mean you'd want to try a \"cased\" model.\n",
    "* **Maximum sequence length (MAX_SEQ_LEN):**<br>\n",
    "Values that can be used for MAX_SEQ_LENGTH are 64, 128, or 256.  Larger models (BERT-large, Megatron) may require a smaller MAX_SEQ_LENGTH to avoid an out-of-memory error.\n",
    "* **Number of Classes (NUM_CLASSES):**<br>\n",
    "For the Federalist Papers, we are only concerned with HAMILTON and MADISON.  The papers by John Jay have been excluded from the dataset.\n",
    "* **Batch size (BATCH_SIZE):**<br>\n",
    "Larger batch sizes train faster, but large language models tend to use up the available memory quickly.\n",
    "* **Memory usage:**<br>\n",
    "Some of the models are very large.   If you get \"RuntimeError: CUDA out of memory\" during training, you'll know you need to reduce the batch size, sequence length, and/or choose a smaller language model, restart the kernel, and try again from the beginning of the notebook.\n",
    "* **Accuracy and loss:**<br>\n",
    "It is definitely possible to achieve 95% or more model accuracy for this project.  In addition to changes in accuracy as the model trains, pay attention to the loss value.  You want the loss value to be dropping and getting very small for best results.\n",
    "* **Number of epochs (NUM_EPOCHS):**<br>\n",
    "You may need to run more epochs for your model (or not!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful utilities for grading\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "def get_latest_model():  \n",
    "    nemo_model_paths = glob.glob('nemo_experiments/TextClassification/*/checkpoints/*.nemo')\n",
    "    # Sort newest first\n",
    "    nemo_model_paths.sort(reverse=True)\n",
    "    return nemo_model_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is located in the data directory - see the list in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.tsv   test49.tsv  test51.tsv  test53.tsv  test55.tsv  test57.tsv  train.tsv\n",
      "test.tsv  test50.tsv  test52.tsv  test54.tsv  test56.tsv  test62.tsv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/dli/task/data/federalist_papers_HM'\n",
    "!ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format (graded)\n",
    "The data is not in the correct format for NeMo text classification.  Correct the data and save the new datasets in the DATA_DIR as `train_nemo_format.tsv` and `dev_nemo_format.tsv`.  You do not need to do anything with any of the test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Concerning Dangers from Dissensions Between the States For the Independent Journal .To the People of the State of New York : THE three last numbers of this paper have been dedicated to an enumeration of the dangers to which we should be exposed , in a state of disunion , from the arms and arts of foreign nations .I shall now proceed to delineate dangers of a different and , perhaps , still more alarming kind -- those which will in all probability flow from dissensions between the States themselves , and from domestic factions and convulsions .These have been already in some instances slightly anticipated ; but they deserve a more particular and more full investigation .A man must be far gone in Utopian speculations who can seriously doubt that , if these States should either be wholly disunited , or only united in partial confederacies , the subdivisions into which they might be thrown would have frequent and violent contests with each other .To presume a want of motives for such contests as an argument against their existence , would be to forget that men are ambitious , vindictive , and rapacious .To look for a continuation of harmony between a number of independent , unconnected sovereignties in the same neighborhood , would be to disregard the uniform course of human events , and to set at defiance the accumulated experience of ages .The causes of hostility among nations are innumerable .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are some which have a general and almost constant operation upon the collective bodies of society .Of this description are the love of power or the desire of pre-eminence and dominion -- the jealousy of power , or the desire of equality and safety .There are others which have a more circumscribed though an equally operative influence within their spheres .Such are the rivalships and competitions of commerce between commercial nations .And there are others , not less numerous than either of the former , which take their origin entirely in private passions ; in the attachments , enmities , interests , hopes , and fears of leading individuals in the communities of which they are members .Men of this class , whether the favorites of a king or of a people , have in too many instances abused the confidence they possessed ; and assuming the pretext of some public motive , have not scrupled to sacrifice the national tranquillity to personal advantage or personal gratification .The celebrated Pericles , in compliance with the resentment of a prostitute,1 at the expense of much of the blood and treasure of his countrymen , attacked , vanquished , and destroyed the city of the SAMNIANS .The same man , stimulated by private pique against the MEGARENSIANS,2 another nation of Greece , or to avoid a prosecution with which he was threatened as an accomplice of a supposed theft of the statuary Phidias,3 or to get rid of the accusations prepared to be brought against him for dissipating the funds of the state in the purchase of popularity,4 or from a combination of all these causes , was the primitive author of that famous and fatal war , distinguished in the Grecian annals by the name of the PELOPONNESIAN war ; which , after various vicissitudes , intermissions , and renewals , terminated in the ruin of the Athenian commonwealth .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The ambitious cardinal , who was prime minister to Henry VIII. , permitting his vanity to aspire to the triple crown,5 entertained hopes of succeeding in the acquisition of that splendid prize by the influence of the Emperor Charles V. To secure the favor and interest of this enterprising and powerful monarch , he precipitated England into a war with France , contrary to the plainest dictates of policy , and at the hazard of the safety and independence , as well of the kingdom over which he presided by his counsels , as of Europe in general .For if there ever was a sovereign who bid fair to realize the project of universal monarchy , it was the Emperor Charles V. , of whose intrigues Wolsey was at once the instrument and the dupe .The influence which the bigotry of one female,6 the petulance of another,7 and the cabals of a third,8 had in the contemporary policy , ferments , and pacifications , of a considerable part of Europe , are topics that have been too often descanted upon not to be generally known .To multiply examples of the agency of personal considerations in the production of great national events , either foreign or domestic , according to their direction , would be an unnecessary waste of time .Those who have but a superficial acquaintance with the sources from which they are to be drawn , will themselves recollect a variety of instances ; and those who have a tolerable knowledge of human nature will not stand in need of such lights to form their opinion either of the reality or extent of that agency .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perhaps , however , a reference , tending to illustrate the general principle , may with propriety be made to a case which has lately happened among ourselves .If Shays had not been a DESPERATE DEBTOR , it is much to be doubted whether Massachusetts would have been plunged into a civil war .But notwithstanding the concurring testimony of experience , in this particular , there are still to be found visionary or designing men , who stand ready to advocate the paradox of perpetual peace between the States , though dismembered and alienated from each other .The genius of republics ( say they ) is pacific ; the spirit of commerce has a tendency to soften the manners of men , and to extinguish those inflammable humors which have so often kindled into wars .Commercial republics , like ours , will never be disposed to waste themselves in ruinous contentions with each other .They will be governed by mutual interest , and will cultivate a spirit of mutual amity and concord .Is it not ( we may ask these projectors in politics ) the true interest of all nations to cultivate the same benevolent and philosophic spirit ? If this be their true interest , have they in fact pursued it ? Has it not , on the contrary , invariably been found that momentary passions , and immediate interest , have a more active and imperious control over human conduct than general or remote considerations of policy , utility or justice ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have republics in practice been less addicted to war than monarchies ? Are not the former administered by MEN as well as the latter ? Are there not aversions , predilections , rivalships , and desires of unjust acquisitions , that affect nations as well as kings ? Are not popular assemblies frequently subject to the impulses of rage , resentment , jealousy , avarice , and of other irregular and violent propensities ? Is it not well known that their determinations are often governed by a few individuals in whom they place confidence , and are , of course , liable to be tinctured by the passions and views of those individuals ? Has commerce hitherto done anything more than change the objects of war ? Is not the love of wealth as domineering and enterprising a passion as that of power or glory ? Have there not been as many wars founded upon commercial motives since that has become the prevailing system of nations , as were before occasioned by the cupidity of territory or dominion ? Has not the spirit of commerce , in many instances , administered new incentives to the appetite , both for the one and for the other ? Let experience , the least fallible guide of human opinions , be appealed to for an answer to these inquiries .Sparta , Athens , Rome , and Carthage were all republics ; two of them , Athens and Carthage , of the commercial kind .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Should the representatives or people , therefore , of the smaller States oppose at any time a reasonable addition of members , a coalition of a very few States will be sufficient to overrule the opposition ; a coalition which , notwithstanding the rivalship and local prejudices which might prevent it on ordinary occasions , would not fail to take place , when not merely prompted by common interest , but justified by equity and the principles of the Constitution .It may be alleged , perhaps , that the Senate would be prompted by like motives to an adverse coalition ; and as their concurrence would be indispensable , the just and constitutional views of the other branch might be defeated .This is the difficulty which has probably created the most serious apprehensions in the jealous friends of a numerous representation .Fortunately it is among the difficulties which , existing only in appearance , vanish on a close and accurate inspection .The following reflections will , if I mistake not , be admitted to be conclusive and satisfactory on this point .Notwithstanding the equal authority which will subsist between the two houses on all legislative subjects , except the originating of money bills , it can not be doubted that the House , composed of the greater number of members , when supported by the more powerful States , and speaking the known and determined sense of a majority of the people , will have no small advantage in a question depending on the comparative firmness of the two houses .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>These considerations seem to afford ample security on this subject , and ought alone to satisfy all the doubts and fears which have been indulged with regard to it .Admitting , however , that they should all be insufficient to subdue the unjust policy of the smaller States , or their predominant influence in the councils of the Senate , a constitutional and infallible resource still remains with the larger States , by which they will be able at all times to accomplish their just purposes .The House of Representatives can not only refuse , but they alone can propose , the supplies requisite for the support of government .They , in a word , hold the purse that powerful instrument by which we behold , in the history of the British Constitution , an infant and humble representation of the people gradually enlarging the sphere of its activity and importance , and finally reducing , as far as it seems to have wished , all the overgrown prerogatives of the other branches of the government .This power over the purse may , in fact , be regarded as the most complete and effectual weapon with which any constitution can arm the immediate representatives of the people , for obtaining a redress of every grievance , and for carrying into effect every just and salutary measure .But will not the House of Representatives be as much interested as the Senate in maintaining the government in its proper functions , and will they not therefore be unwilling to stake its existence or its reputation on the pliancy of the Senate ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Or , if such a trial of firmness between the two branches were hazarded , would not the one be as likely first to yield as the other ? These questions will create no difficulty with those who reflect that in all cases the smaller the number , and the more permanent and conspicuous the station , of men in power , the stronger must be the interest which they will individually feel in whatever concerns the government .Those who represent the dignity of their country in the eyes of other nations , will be particularly sensible to every prospect of public danger , or of dishonorable stagnation in public affairs .To those causes we are to ascribe the continual triumph of the British House of Commons over the other branches of the government , whenever the engine of a money bill has been employed .An absolute inflexibility on the side of the latter , although it could not have failed to involve every department of the state in the general confusion , has neither been apprehended nor experienced .The utmost degree of firmness that can be displayed by the federal Senate or President , will not be more than equal to a resistance in which they will be supported by constitutional and patriotic principles .In this review of the Constitution of the House of Representatives , I have passed over the circumstances of economy , which , in the present state of affairs , might have had some effect in lessening the temporary number of representatives , and a disregard of which would probably have been as rich a theme of declamation against the Constitution as has been shown by the smallness of the number proposed .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>I omit also any remarks on the difficulty which might be found , under present circumstances , in engaging in the federal service a large number of such characters as the people will probably elect .One observation , however , I must be permitted to add on this subject as claiming , in my judgment , a very serious attention .It is , that in all legislative assemblies the greater the number composing them may be , the fewer will be the men who will in fact direct their proceedings .In the first place , the more numerous an assembly may be , of whatever characters composed , the greater is known to be the ascendency of passion over reason .In the next place , the larger the number , the greater will be the proportion of members of limited information and of weak capacities .Now , it is precisely on characters of this description that the eloquence and address of the few are known to act with all their force .In the ancient republics , where the whole body of the people assembled in person , a single orator , or an artful statesman , was generally seen to rule with as complete a sway as if a sceptre had been placed in his single hand .On the same principle , the more multitudinous a representative assembly may be rendered , the more it will partake of the infirmities incident to collective meetings of the people .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Ignorance will be the dupe of cunning , and passion the slave of sophistry and declamation .The people can never err more than in supposing that by multiplying their representatives beyond a certain limit , they strengthen the barrier against the government of a few .Experience will forever admonish them that , on the contrary , AFTER SECURING A SUFFICIENT NUMBER FOR THE PURPOSES OF SAFETY , OF LOCAL INFORMATION , AND OF DIFFUSIVE SYMPATHY WITH THE WHOLE SOCIETY , they will counteract their own views by every addition to their representatives .The countenance of the government may become more democratic , but the soul that animates it will be more oligarchic .The machine will be enlarged , but the fewer , and often the more secret , will be the springs by which its motions are directed .As connected with the objection against the number of representatives , may properly be here noticed , that which has been suggested against the number made competent for legislative business .It has been said that more than a majority ought to have been required for a quorum ; and in particular cases , if not in all , more than a majority of a quorum for a decision .That some advantages might have resulted from such a precaution , can not be denied .It might have been an additional shield to some particular interests , and another obstacle generally to hasty and partial measures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                        Concerning Dangers from Dissensions Between the States For the Independent Journal .To the People of the State of New York : THE three last numbers of this paper have been dedicated to an enumeration of the dangers to which we should be exposed , in a state of disunion , from the arms and arts of foreign nations .I shall now proceed to delineate dangers of a different and , perhaps , still more alarming kind -- those which will in all probability flow from dissensions between the States themselves , and from domestic factions and convulsions .These have been already in some instances slightly anticipated ; but they deserve a more particular and more full investigation .A man must be far gone in Utopian speculations who can seriously doubt that , if these States should either be wholly disunited , or only united in partial confederacies , the subdivisions into which they might be thrown would have frequent and violent contests with each other .To presume a want of motives for such contests as an argument against their existence , would be to forget that men are ambitious , vindictive , and rapacious .To look for a continuation of harmony between a number of independent , unconnected sovereignties in the same neighborhood , would be to disregard the uniform course of human events , and to set at defiance the accumulated experience of ages .The causes of hostility among nations are innumerable .   \n",
       "1    There are some which have a general and almost constant operation upon the collective bodies of society .Of this description are the love of power or the desire of pre-eminence and dominion -- the jealousy of power , or the desire of equality and safety .There are others which have a more circumscribed though an equally operative influence within their spheres .Such are the rivalships and competitions of commerce between commercial nations .And there are others , not less numerous than either of the former , which take their origin entirely in private passions ; in the attachments , enmities , interests , hopes , and fears of leading individuals in the communities of which they are members .Men of this class , whether the favorites of a king or of a people , have in too many instances abused the confidence they possessed ; and assuming the pretext of some public motive , have not scrupled to sacrifice the national tranquillity to personal advantage or personal gratification .The celebrated Pericles , in compliance with the resentment of a prostitute,1 at the expense of much of the blood and treasure of his countrymen , attacked , vanquished , and destroyed the city of the SAMNIANS .The same man , stimulated by private pique against the MEGARENSIANS,2 another nation of Greece , or to avoid a prosecution with which he was threatened as an accomplice of a supposed theft of the statuary Phidias,3 or to get rid of the accusations prepared to be brought against him for dissipating the funds of the state in the purchase of popularity,4 or from a combination of all these causes , was the primitive author of that famous and fatal war , distinguished in the Grecian annals by the name of the PELOPONNESIAN war ; which , after various vicissitudes , intermissions , and renewals , terminated in the ruin of the Athenian commonwealth .   \n",
       "2                                                                                                                                                                                                                                                                                                                           The ambitious cardinal , who was prime minister to Henry VIII. , permitting his vanity to aspire to the triple crown,5 entertained hopes of succeeding in the acquisition of that splendid prize by the influence of the Emperor Charles V. To secure the favor and interest of this enterprising and powerful monarch , he precipitated England into a war with France , contrary to the plainest dictates of policy , and at the hazard of the safety and independence , as well of the kingdom over which he presided by his counsels , as of Europe in general .For if there ever was a sovereign who bid fair to realize the project of universal monarchy , it was the Emperor Charles V. , of whose intrigues Wolsey was at once the instrument and the dupe .The influence which the bigotry of one female,6 the petulance of another,7 and the cabals of a third,8 had in the contemporary policy , ferments , and pacifications , of a considerable part of Europe , are topics that have been too often descanted upon not to be generally known .To multiply examples of the agency of personal considerations in the production of great national events , either foreign or domestic , according to their direction , would be an unnecessary waste of time .Those who have but a superficial acquaintance with the sources from which they are to be drawn , will themselves recollect a variety of instances ; and those who have a tolerable knowledge of human nature will not stand in need of such lights to form their opinion either of the reality or extent of that agency .   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                Perhaps , however , a reference , tending to illustrate the general principle , may with propriety be made to a case which has lately happened among ourselves .If Shays had not been a DESPERATE DEBTOR , it is much to be doubted whether Massachusetts would have been plunged into a civil war .But notwithstanding the concurring testimony of experience , in this particular , there are still to be found visionary or designing men , who stand ready to advocate the paradox of perpetual peace between the States , though dismembered and alienated from each other .The genius of republics ( say they ) is pacific ; the spirit of commerce has a tendency to soften the manners of men , and to extinguish those inflammable humors which have so often kindled into wars .Commercial republics , like ours , will never be disposed to waste themselves in ruinous contentions with each other .They will be governed by mutual interest , and will cultivate a spirit of mutual amity and concord .Is it not ( we may ask these projectors in politics ) the true interest of all nations to cultivate the same benevolent and philosophic spirit ? If this be their true interest , have they in fact pursued it ? Has it not , on the contrary , invariably been found that momentary passions , and immediate interest , have a more active and imperious control over human conduct than general or remote considerations of policy , utility or justice ?   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Have republics in practice been less addicted to war than monarchies ? Are not the former administered by MEN as well as the latter ? Are there not aversions , predilections , rivalships , and desires of unjust acquisitions , that affect nations as well as kings ? Are not popular assemblies frequently subject to the impulses of rage , resentment , jealousy , avarice , and of other irregular and violent propensities ? Is it not well known that their determinations are often governed by a few individuals in whom they place confidence , and are , of course , liable to be tinctured by the passions and views of those individuals ? Has commerce hitherto done anything more than change the objects of war ? Is not the love of wealth as domineering and enterprising a passion as that of power or glory ? Have there not been as many wars founded upon commercial motives since that has become the prevailing system of nations , as were before occasioned by the cupidity of territory or dominion ? Has not the spirit of commerce , in many instances , administered new incentives to the appetite , both for the one and for the other ? Let experience , the least fallible guide of human opinions , be appealed to for an answer to these inquiries .Sparta , Athens , Rome , and Carthage were all republics ; two of them , Athens and Carthage , of the commercial kind .   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ...   \n",
       "497                                                                                                                                                                                                                                                                                                                                                  Should the representatives or people , therefore , of the smaller States oppose at any time a reasonable addition of members , a coalition of a very few States will be sufficient to overrule the opposition ; a coalition which , notwithstanding the rivalship and local prejudices which might prevent it on ordinary occasions , would not fail to take place , when not merely prompted by common interest , but justified by equity and the principles of the Constitution .It may be alleged , perhaps , that the Senate would be prompted by like motives to an adverse coalition ; and as their concurrence would be indispensable , the just and constitutional views of the other branch might be defeated .This is the difficulty which has probably created the most serious apprehensions in the jealous friends of a numerous representation .Fortunately it is among the difficulties which , existing only in appearance , vanish on a close and accurate inspection .The following reflections will , if I mistake not , be admitted to be conclusive and satisfactory on this point .Notwithstanding the equal authority which will subsist between the two houses on all legislative subjects , except the originating of money bills , it can not be doubted that the House , composed of the greater number of members , when supported by the more powerful States , and speaking the known and determined sense of a majority of the people , will have no small advantage in a question depending on the comparative firmness of the two houses .   \n",
       "498                                                                                                                                                                                                                                                                                                                                    These considerations seem to afford ample security on this subject , and ought alone to satisfy all the doubts and fears which have been indulged with regard to it .Admitting , however , that they should all be insufficient to subdue the unjust policy of the smaller States , or their predominant influence in the councils of the Senate , a constitutional and infallible resource still remains with the larger States , by which they will be able at all times to accomplish their just purposes .The House of Representatives can not only refuse , but they alone can propose , the supplies requisite for the support of government .They , in a word , hold the purse that powerful instrument by which we behold , in the history of the British Constitution , an infant and humble representation of the people gradually enlarging the sphere of its activity and importance , and finally reducing , as far as it seems to have wished , all the overgrown prerogatives of the other branches of the government .This power over the purse may , in fact , be regarded as the most complete and effectual weapon with which any constitution can arm the immediate representatives of the people , for obtaining a redress of every grievance , and for carrying into effect every just and salutary measure .But will not the House of Representatives be as much interested as the Senate in maintaining the government in its proper functions , and will they not therefore be unwilling to stake its existence or its reputation on the pliancy of the Senate ?   \n",
       "499                                                                                                                                                                                                                                        Or , if such a trial of firmness between the two branches were hazarded , would not the one be as likely first to yield as the other ? These questions will create no difficulty with those who reflect that in all cases the smaller the number , and the more permanent and conspicuous the station , of men in power , the stronger must be the interest which they will individually feel in whatever concerns the government .Those who represent the dignity of their country in the eyes of other nations , will be particularly sensible to every prospect of public danger , or of dishonorable stagnation in public affairs .To those causes we are to ascribe the continual triumph of the British House of Commons over the other branches of the government , whenever the engine of a money bill has been employed .An absolute inflexibility on the side of the latter , although it could not have failed to involve every department of the state in the general confusion , has neither been apprehended nor experienced .The utmost degree of firmness that can be displayed by the federal Senate or President , will not be more than equal to a resistance in which they will be supported by constitutional and patriotic principles .In this review of the Constitution of the House of Representatives , I have passed over the circumstances of economy , which , in the present state of affairs , might have had some effect in lessening the temporary number of representatives , and a disregard of which would probably have been as rich a theme of declamation against the Constitution as has been shown by the smallness of the number proposed .   \n",
       "500                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         I omit also any remarks on the difficulty which might be found , under present circumstances , in engaging in the federal service a large number of such characters as the people will probably elect .One observation , however , I must be permitted to add on this subject as claiming , in my judgment , a very serious attention .It is , that in all legislative assemblies the greater the number composing them may be , the fewer will be the men who will in fact direct their proceedings .In the first place , the more numerous an assembly may be , of whatever characters composed , the greater is known to be the ascendency of passion over reason .In the next place , the larger the number , the greater will be the proportion of members of limited information and of weak capacities .Now , it is precisely on characters of this description that the eloquence and address of the few are known to act with all their force .In the ancient republics , where the whole body of the people assembled in person , a single orator , or an artful statesman , was generally seen to rule with as complete a sway as if a sceptre had been placed in his single hand .On the same principle , the more multitudinous a representative assembly may be rendered , the more it will partake of the infirmities incident to collective meetings of the people .   \n",
       "501                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Ignorance will be the dupe of cunning , and passion the slave of sophistry and declamation .The people can never err more than in supposing that by multiplying their representatives beyond a certain limit , they strengthen the barrier against the government of a few .Experience will forever admonish them that , on the contrary , AFTER SECURING A SUFFICIENT NUMBER FOR THE PURPOSES OF SAFETY , OF LOCAL INFORMATION , AND OF DIFFUSIVE SYMPATHY WITH THE WHOLE SOCIETY , they will counteract their own views by every addition to their representatives .The countenance of the government may become more democratic , but the soul that animates it will be more oligarchic .The machine will be enlarged , but the fewer , and often the more secret , will be the springs by which its motions are directed .As connected with the objection against the number of representatives , may properly be here noticed , that which has been suggested against the number made competent for legislative business .It has been said that more than a majority ought to have been required for a quorum ; and in particular cases , if not in all , more than a majority of a quorum for a decision .That some advantages might have resulted from such a precaution , can not be denied .It might have been an additional shield to some particular interests , and another obstacle generally to hasty and partial measures .   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "497      1  \n",
       "498      1  \n",
       "499      1  \n",
       "500      1  \n",
       "501      1  \n",
       "\n",
       "[502 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the format for train.tsv and dev.tsv\n",
    "#   and save the updates in train_nemo_format.tsv and dev_nemo_format.tsv\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "train_df =  pd.read_csv(DATA_DIR + '/train.tsv', sep='\\t',)\n",
    "train_df.to_csv(DATA_DIR + '/train_nemo_format.tsv', sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "dev_df =  pd.read_csv(DATA_DIR + '/dev.tsv', sep='\\t')\n",
    "dev_df.to_csv(DATA_DIR + '/dev_nemo_format.tsv', sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "train_nemo_format.tsv sample\n",
      "*****\n",
      "Concerning Dangers from Dissensions Between the States For the Independent Journal .To the People of the State of New York : THE three last numbers of this paper have been dedicated to an enumeration of the dangers to which we should be exposed , in a state of disunion , from the arms and arts of foreign nations .I shall now proceed to delineate dangers of a different and , perhaps , still more alarming kind -- those which will in all probability flow from dissensions between the States themselves , and from domestic factions and convulsions .These have been already in some instances slightly anticipated ; but they deserve a more particular and more full investigation .A man must be far gone in Utopian speculations who can seriously doubt that , if these States should either be wholly disunited , or only united in partial confederacies , the subdivisions into which they might be thrown would have frequent and violent contests with each other .To presume a want of motives for such contests as an argument against their existence , would be to forget that men are ambitious , vindictive , and rapacious .To look for a continuation of harmony between a number of independent , unconnected sovereignties in the same neighborhood , would be to disregard the uniform course of human events , and to set at defiance the accumulated experience of ages .The causes of hostility among nations are innumerable .\t0\n",
      "There are some which have a general and almost constant operation upon the collective bodies of society .Of this description are the love of power or the desire of pre-eminence and dominion -- the jealousy of power , or the desire of equality and safety .There are others which have a more circumscribed though an equally operative influence within their spheres .Such are the rivalships and competitions of commerce between commercial nations .And there are others , not less numerous than either of the former , which take their origin entirely in private passions ; in the attachments , enmities , interests , hopes , and fears of leading individuals in the communities of which they are members .Men of this class , whether the favorites of a king or of a people , have in too many instances abused the confidence they possessed ; and assuming the pretext of some public motive , have not scrupled to sacrifice the national tranquillity to personal advantage or personal gratification .The celebrated Pericles , in compliance with the resentment of a prostitute,1 at the expense of much of the blood and treasure of his countrymen , attacked , vanquished , and destroyed the city of the SAMNIANS .The same man , stimulated by private pique against the MEGARENSIANS,2 another nation of Greece , or to avoid a prosecution with which he was threatened as an accomplice of a supposed theft of the statuary Phidias,3 or to get rid of the accusations prepared to be brought against him for dissipating the funds of the state in the purchase of popularity,4 or from a combination of all these causes , was the primitive author of that famous and fatal war , distinguished in the Grecian annals by the name of the PELOPONNESIAN war ; which , after various vicissitudes , intermissions , and renewals , terminated in the ruin of the Athenian commonwealth .\t0\n",
      "The ambitious cardinal , who was prime minister to Henry VIII. , permitting his vanity to aspire to the triple crown,5 entertained hopes of succeeding in the acquisition of that splendid prize by the influence of the Emperor Charles V. To secure the favor and interest of this enterprising and powerful monarch , he precipitated England into a war with France , contrary to the plainest dictates of policy , and at the hazard of the safety and independence , as well of the kingdom over which he presided by his counsels , as of Europe in general .For if there ever was a sovereign who bid fair to realize the project of universal monarchy , it was the Emperor Charles V. , of whose intrigues Wolsey was at once the instrument and the dupe .The influence which the bigotry of one female,6 the petulance of another,7 and the cabals of a third,8 had in the contemporary policy , ferments , and pacifications , of a considerable part of Europe , are topics that have been too often descanted upon not to be generally known .To multiply examples of the agency of personal considerations in the production of great national events , either foreign or domestic , according to their direction , would be an unnecessary waste of time .Those who have but a superficial acquaintance with the sources from which they are to be drawn , will themselves recollect a variety of instances ; and those who have a tolerable knowledge of human nature will not stand in need of such lights to form their opinion either of the reality or extent of that agency .\t0\n",
      "\n",
      "\n",
      "*****\n",
      "dev_nemo_format.tsv sample\n",
      "*****\n",
      "There have been , if I may so express it , almost as many popular as royal wars .The cries of the nation and the importunities of their representatives have , upon various occasions , dragged their monarchs into war , or continued them in it , contrary to their inclinations , and sometimes contrary to the real interests of the State .In that memorable struggle for superiority between the rival houses of AUSTRIA and BOURBON , which so long kept Europe in a flame , it is well known that the antipathies of the English against the French , seconding the ambition , or rather the avarice , of a favorite leader,10 protracted the war beyond the limits marked out by sound policy , and for a considerable time in opposition to the views of the court .The wars of these two last-mentioned nations have in a great measure grown out of commercial considerations , -- the desire of supplanting and the fear of being supplanted , either in particular branches of traffic or in the general advantages of trade and navigation .From this summary of what has taken place in other countries , whose situations have borne the nearest resemblance to our own , what reason can we have to confide in those reveries which would seduce us into an expectation of peace and cordiality between the members of the present confederacy , in a state of separation ? Have we not already seen enough of the fallacy and extravagance of those idle theories which have amused us with promises of an exemption from the imperfections , weaknesses and evils incident to society in every shape ?\t0\n",
      "They would , at the same time , be necessitated to strengthen the executive arm of government , in doing which their constitutions would acquire a progressive direction toward monarchy .It is of the nature of war to increase the executive at the expense of the legislative authority .The expedients which have been mentioned would soon give the States or confederacies that made use of them a superiority over their neighbors .Small states , or states of less natural strength , under vigorous governments , and with the assistance of disciplined armies , have often triumphed over large states , or states of greater natural strength , which have been destitute of these advantages .Neither the pride nor the safety of the more important States or confederacies would permit them long to submit to this mortifying and adventitious superiority .They would quickly resort to means similar to those by which it had been effected , to reinstate themselves in their lost pre-eminence .Thus , we should , in a little time , see established in every part of this country the same engines of despotism which have been the scourge of the Old World .This , at least , would be the natural course of things ; and our reasonings will be the more likely to be just , in proportion as they are accommodated to this standard .These are not vague inferences drawn from supposed or speculative defects in a Constitution , the whole power of which is lodged in the hands of a people , or their representatives and delegates , but they are solid conclusions , drawn from the natural and necessary progress of human affairs .\t0\n",
      "Such a point gained from the British government , and which could not be expected without an equivalent in exemptions and immunities in our markets , would be likely to have a correspondent effect on the conduct of other nations , who would not be inclined to see themselves altogether supplanted in our trade .A further resource for influencing the conduct of European nations toward us , in this respect , would arise from the establishment of a federal navy .There can be no doubt that the continuance of the Union under an efficient government would put it in our power , at a period not very distant , to create a navy which , if it could not vie with those of the great maritime powers , would at least be of respectable weight if thrown into the scale of either of two contending parties .This would be more peculiarly the case in relation to operations in the West Indies .A few ships of the line , sent opportunely to the reinforcement of either side , would often be sufficient to decide the fate of a campaign , on the event of which interests of the greatest magnitude were suspended .Our position is , in this respect , a most commanding one .And if to this consideration we add that of the usefulness of supplies from this country , in the prosecution of military operations in the West Indies , it will readily be perceived that a situation so favorable would enable us to bargain with great advantage for commercial privileges .\t0\n"
     ]
    }
   ],
   "source": [
    "# check your work\n",
    "print(\"*****\\ntrain_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $DATA_DIR/train_nemo_format.tsv\n",
    "print(\"\\n\\n*****\\ndev_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $DATA_DIR/dev_nemo_format.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to save for assessment- DO NOT CHANGE\n",
    "import os.path\n",
    "DATA_DIR = '/dli/task/data/federalist_papers_HM'\n",
    "step1 = []\n",
    "try:\n",
    "    with open(os.path.join(DATA_DIR,'train_nemo_format.tsv')) as f:\n",
    "        content = f.readlines()\n",
    "        step1 += content[:2]\n",
    "    with open(os.path.join(DATA_DIR,'dev_nemo_format.tsv')) as f:\n",
    "        content = f.readlines()\n",
    "        step1 += content[:2]\n",
    "except:\n",
    "    pass\n",
    "                \n",
    "with open(\"my_assessment/step1.json\", \"w\") as outfile: \n",
    "    json.dump(step1, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Prepare the Model Configuration\n",
    "Review the default model configuration and available language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nemo_path: text_classification_model.nemo\n",
      "tokenizer:\n",
      "  tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "  vocab_file: null\n",
      "  tokenizer_model: null\n",
      "  special_tokens: null\n",
      "language_model:\n",
      "  pretrained_model_name: bert-base-uncased\n",
      "  lm_checkpoint: null\n",
      "  config_file: null\n",
      "  config: null\n",
      "classifier_head:\n",
      "  num_output_layers: 2\n",
      "  fc_dropout: 0.1\n",
      "class_labels:\n",
      "  class_labels_file: null\n",
      "dataset:\n",
      "  num_classes: ???\n",
      "  do_lower_case: false\n",
      "  max_seq_length: 256\n",
      "  class_balancing: null\n",
      "  use_cache: false\n",
      "train_ds:\n",
      "  file_path: null\n",
      "  batch_size: 64\n",
      "  shuffle: true\n",
      "  num_samples: -1\n",
      "  num_workers: 3\n",
      "  drop_last: false\n",
      "  pin_memory: false\n",
      "validation_ds:\n",
      "  file_path: null\n",
      "  batch_size: 64\n",
      "  shuffle: false\n",
      "  num_samples: -1\n",
      "  num_workers: 3\n",
      "  drop_last: false\n",
      "  pin_memory: false\n",
      "test_ds:\n",
      "  file_path: null\n",
      "  batch_size: 64\n",
      "  shuffle: false\n",
      "  num_samples: -1\n",
      "  num_workers: 3\n",
      "  drop_last: false\n",
      "  pin_memory: false\n",
      "optim:\n",
      "  name: adam\n",
      "  lr: 2.0e-05\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  weight_decay: 0.01\n",
      "  sched:\n",
      "    name: WarmupAnnealing\n",
      "    warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "infer_samples:\n",
      "- by the end of no such thing the audience , like beatrice , has a watchful affection\n",
      "  for the monster .\n",
      "- director rob marshall went out gunning to make a great one .\n",
      "- uneasy mishmash of styles and genres .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the default model portion of the config file\n",
    "CONFIG_DIR = \"/dli/task/nemo/examples/nlp/text_classification/conf\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "\n",
    "config = OmegaConf.load(CONFIG_DIR + \"/\" + CONFIG_FILE)\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['megatron-bert-345m-uncased',\n",
       " 'megatron-bert-345m-cased',\n",
       " 'megatron-bert-uncased',\n",
       " 'megatron-bert-cased',\n",
       " 'biomegatron-bert-345m-uncased',\n",
       " 'biomegatron-bert-345m-cased',\n",
       " 'bert-base-uncased',\n",
       " 'bert-large-uncased',\n",
       " 'bert-base-cased',\n",
       " 'bert-large-cased',\n",
       " 'bert-base-multilingual-uncased',\n",
       " 'bert-base-multilingual-cased',\n",
       " 'bert-base-chinese',\n",
       " 'bert-base-german-cased',\n",
       " 'bert-large-uncased-whole-word-masking',\n",
       " 'bert-large-cased-whole-word-masking',\n",
       " 'bert-large-uncased-whole-word-masking-finetuned-squad',\n",
       " 'bert-large-cased-whole-word-masking-finetuned-squad',\n",
       " 'bert-base-cased-finetuned-mrpc',\n",
       " 'bert-base-german-dbmdz-cased',\n",
       " 'bert-base-german-dbmdz-uncased',\n",
       " 'cl-tohoku/bert-base-japanese',\n",
       " 'cl-tohoku/bert-base-japanese-whole-word-masking',\n",
       " 'cl-tohoku/bert-base-japanese-char',\n",
       " 'cl-tohoku/bert-base-japanese-char-whole-word-masking',\n",
       " 'TurkuNLP/bert-base-finnish-cased-v1',\n",
       " 'TurkuNLP/bert-base-finnish-uncased-v1',\n",
       " 'wietsedv/bert-base-dutch-cased',\n",
       " 'distilbert-base-uncased',\n",
       " 'distilbert-base-uncased-distilled-squad',\n",
       " 'distilbert-base-cased',\n",
       " 'distilbert-base-cased-distilled-squad',\n",
       " 'distilbert-base-german-cased',\n",
       " 'distilbert-base-multilingual-cased',\n",
       " 'distilbert-base-uncased-finetuned-sst-2-english',\n",
       " 'roberta-base',\n",
       " 'roberta-large',\n",
       " 'roberta-large-mnli',\n",
       " 'distilroberta-base',\n",
       " 'roberta-base-openai-detector',\n",
       " 'roberta-large-openai-detector',\n",
       " 'albert-base-v1',\n",
       " 'albert-large-v1',\n",
       " 'albert-xlarge-v1',\n",
       " 'albert-xxlarge-v1',\n",
       " 'albert-base-v2',\n",
       " 'albert-large-v2',\n",
       " 'albert-xlarge-v2',\n",
       " 'albert-xxlarge-v2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what BERT-like language models are available\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "nemo_nlp.modules.get_pretrained_lm_models_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the values\n",
    "NUM_CLASSES = 2\n",
    "MAX_SEQ_LENGTH = 64\n",
    "BATCH_SIZE = 64\n",
    "PATH_TO_TRAIN_FILE = \"/dli/task/data/federalist_papers_HM/train_nemo_format.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/dli/task/data/federalist_papers_HM/dev_nemo_format.tsv\"\n",
    "PRETRAINED_MODEL_NAME = 'bert-large-cased' # change as desired\n",
    "LR = 1e-4 # change as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to save for assessment- DO NOT CHANGE\n",
    "with open(\"my_assessment/step2.json\", \"w\") as outfile: \n",
    "    json.dump([MAX_SEQ_LENGTH, NUM_CLASSES, BATCH_SIZE], outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Prepare the Trainer Configuration\n",
    "Review the default trainer and exp_manager configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: 1\n",
      "num_nodes: 1\n",
      "max_epochs: 100\n",
      "max_steps: null\n",
      "accumulate_grad_batches: 1\n",
      "gradient_clip_val: 0.0\n",
      "amp_level: O0\n",
      "precision: 32\n",
      "accelerator: ddp\n",
      "log_every_n_steps: 1\n",
      "val_check_interval: 1.0\n",
      "resume_from_checkpoint: null\n",
      "num_sanity_val_steps: 0\n",
      "checkpoint_callback: false\n",
      "logger: false\n",
      "\n",
      "exp_dir: null\n",
      "name: TextClassification\n",
      "create_tensorboard_logger: true\n",
      "create_checkpoint_callback: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config.trainer))\n",
    "print(OmegaConf.to_yaml(config.exp_manager))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters (graded)\n",
    "Set the automatic mixed precision to level 1 with FP16 precision.  Set the MAX_EPOCHS to a reasonable level, perhaps between 5 and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the values\n",
    "MAX_EPOCHS = 20\n",
    "AMP_LEVEL = 'O1'\n",
    "PRECISION = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to save for assessment - DO NOT CHANGE\n",
    "with open(\"my_assessment/step3.json\", \"w\") as outfile: \n",
    "    json.dump([MAX_EPOCHS, AMP_LEVEL, PRECISION], outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Step 4: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Trainer (graded)\n",
    "Then train and run the save cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-10 10:44:31 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/omegaconf/basecontainer.py:225: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
      "    Use OmegaConf.to_yaml(cfg)\n",
      "    \n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_with_bert:110] \n",
      "    Config Params:\n",
      "    trainer:\n",
      "      gpus: 1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 20\n",
      "      max_steps: null\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      amp_level: O1\n",
      "      precision: 16\n",
      "      accelerator: ddp\n",
      "      log_every_n_steps: 1\n",
      "      val_check_interval: 1.0\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      checkpoint_callback: false\n",
      "      logger: false\n",
      "    model:\n",
      "      nemo_path: text_classification_model.nemo\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-large-cased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      class_labels:\n",
      "        class_labels_file: null\n",
      "      dataset:\n",
      "        num_classes: 2\n",
      "        do_lower_case: false\n",
      "        max_seq_length: 64\n",
      "        class_balancing: null\n",
      "        use_cache: false\n",
      "      train_ds:\n",
      "        file_path: /dli/task/data/federalist_papers_HM/train_nemo_format.tsv\n",
      "        batch_size: 64\n",
      "        shuffle: true\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      validation_ds:\n",
      "        file_path: /dli/task/data/federalist_papers_HM/dev_nemo_format.tsv\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      test_ds:\n",
      "        file_path: null\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      optim:\n",
      "        name: adam\n",
      "        lr: 2.0e-05\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        weight_decay: 0.01\n",
      "        sched:\n",
      "          name: WarmupAnnealing\n",
      "          warmup_steps: null\n",
      "          warmup_ratio: 0.1\n",
      "          last_epoch: -1\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "      infer_samples: []\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: TextClassification\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "    \n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "[NeMo I 2022-08-10 10:44:31 exp_manager:216] Experiments will be logged at /dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31\n",
      "[NeMo I 2022-08-10 10:44:31 exp_manager:563] TensorboardLogger has been set up\n",
      "Lock 140037139334192 acquired on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n",
      "Downloading: 100%|█████████████████████████████| 762/762 [00:00<00:00, 1.08MB/s]\n",
      "Lock 140037139334192 released on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n",
      "Lock 140037139004960 acquired on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
      "Downloading: 100%|███████████████████████████| 213k/213k [00:00<00:00, 46.6MB/s]\n",
      "Lock 140037139004960 released on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
      "Lock 140037138594928 acquired on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
      "Downloading: 100%|███████████████████████████| 29.0/29.0 [00:00<00:00, 40.6kB/s]\n",
      "Lock 140037138594928 released on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
      "Lock 140037139004768 acquired on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
      "Downloading: 100%|███████████████████████████| 436k/436k [00:00<00:00, 51.7MB/s]\n",
      "Lock 140037139004768 released on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:120] Read 502 examples from /dli/task/data/federalist_papers_HM/train_nemo_format.tsv.\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:239] example 0: ['The', 'system', 'of', 'quotas', 'and', 'requisitions', ',', 'whether', 'it', 'be', 'applied', 'to', 'men', 'or', 'money', ',', 'is', ',', 'in', 'every', 'view', ',', 'a', 'system', 'of', 'imbecility', 'in', 'the', 'Union', ',', 'and', 'of', 'inequality', 'and', 'injustice', 'among', 'the', 'members', '.The', 'right', 'of', 'equal', 'suffrage', 'among', 'the', 'States', 'is', 'another', 'exceptionable', 'part', 'of', 'the', 'Confederation', '.Every', 'idea', 'of', 'proportion', 'and', 'every', 'rule', 'of', 'fair', 'representation', 'conspire', 'to', 'condemn', 'a', 'principle', ',', 'which', 'gives', 'to', 'Rhode', 'Island', 'an', 'equal', 'weight', 'in', 'the', 'scale', 'of', 'power', 'with', 'Massachusetts', ',', 'or', 'Connecticut', ',', 'or', 'New', 'York', ';', 'and', 'to', 'Deleware', 'an', 'equal', 'voice', 'in', 'the', 'national', 'deliberations', 'with', 'Pennsylvania', ',', 'or', 'Virginia', ',', 'or', 'North', 'Carolina', '.Its', 'operation', 'contradicts', 'the', 'fundamental', 'maxim', 'of', 'republican', 'government', ',', 'which', 'requires', 'that', 'the', 'sense', 'of', 'the', 'majority', 'should', 'prevail', '.Sophistry', 'may', 'reply', ',', 'that', 'sovereigns', 'are', 'equal', ',', 'and', 'that', 'a', 'majority', 'of', 'the', 'votes', 'of', 'the', 'States', 'will', 'be', 'a', 'majority', 'of', 'confederated', 'America', '.But', 'this', 'kind', 'of', 'logical', 'legerdemain', 'will', 'never', 'counteract', 'the', 'plain', 'suggestions', 'of', 'justice', 'and', 'common-sense', '.It', 'may', 'happen', 'that', 'this', 'majority', 'of', 'States', 'is', 'a', 'small', 'minority', 'of', 'the', 'people', 'of', 'America', '[', '3', ']', ';', 'and', 'two', 'thirds', 'of', 'the', 'people', 'of', 'America', 'could', 'not', 'long', 'be', 'persuaded', ',', 'upon', 'the', 'credit', 'of', 'artificial', 'distinctions', 'and', 'syllogistic', 'subtleties', ',', 'to', 'submit', 'their', 'interests', 'to', 'the', 'management', 'and', 'disposal', 'of', 'one', 'third', '.The', 'larger', 'States', 'would', 'after', 'a', 'while', 'revolt', 'from', 'the', 'idea', 'of', 'receiving', 'the', 'law', 'from', 'the', 'smaller', '.']\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:240] subtokens: [CLS] The system of quota ##s and re ##quisition ##s , whether it be applied to men or money , is , in every view , a system of im ##be ##ci ##lity in the Union , and of inequality and injustice among the members . The right of equal suffrage among the States is another exception ##able part of the Confederation . Every [SEP]\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:241] input_ids: 101 1109 1449 1104 23690 1116 1105 1231 18540 1116 117 2480 1122 1129 3666 1106 1441 1137 1948 117 1110 117 1107 1451 2458 117 170 1449 1104 13280 3962 6617 11796 1107 1103 1913 117 1105 1104 18610 1105 26991 1621 1103 1484 119 1109 1268 1104 4463 18817 1621 1103 1311 1110 1330 5856 1895 1226 1104 1103 13052 119 4081 102\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:239] example 1: ['To', 'have', 'required', 'the', 'unanimous', 'ratification', 'of', 'the', 'thirteen', 'States', ',', 'would', 'have', 'subjected', 'the', 'essential', 'interests', 'of', 'the', 'whole', 'to', 'the', 'caprice', 'or', 'corruption', 'of', 'a', 'single', 'member', '.It', 'would', 'have', 'marked', 'a', 'want', 'of', 'foresight', 'in', 'the', 'convention', ',', 'which', 'our', 'own', 'experience', 'would', 'have', 'rendered', 'inexcusable', '.Two', 'questions', 'of', 'a', 'very', 'delicate', 'nature', 'present', 'themselves', 'on', 'this', 'occasion', ':', '1', '.On', 'what', 'principle', 'the', 'Confederation', ',', 'which', 'stands', 'in', 'the', 'solemn', 'form', 'of', 'a', 'compact', 'among', 'the', 'States', ',', 'can', 'be', 'superseded', 'without', 'the', 'unanimous', 'consent', 'of', 'the', 'parties', 'to', 'it', '?', '2', '.What', 'relation', 'is', 'to', 'subsist', 'between', 'the', 'nine', 'or', 'more', 'States', 'ratifying', 'the', 'Constitution', ',', 'and', 'the', 'remaining', 'few', 'who', 'do', 'not', 'become', 'parties', 'to', 'it', '?', 'The', 'first', 'question', 'is', 'answered', 'at', 'once', 'by', 'recurring', 'to', 'the', 'absolute', 'necessity', 'of', 'the', 'case', ';', 'to', 'the', 'great', 'principle', 'of', 'self-preservation', ';', 'to', 'the', 'transcendent', 'law', 'of', 'nature', 'and', 'of', 'nature', \"'s\", 'God', ',', 'which', 'declares', 'that', 'the', 'safety', 'and', 'happiness', 'of', 'society', 'are', 'the', 'objects', 'at', 'which', 'all', 'political', 'institutions', 'aim', ',', 'and', 'to', 'which', 'all', 'such', 'institutions', 'must', 'be', 'sacrificed', '.PERHAPS', ',', 'also', ',', 'an', 'answer', 'may', 'be', 'found', 'without', 'searching', 'beyond', 'the', 'principles', 'of', 'the', 'compact', 'itself', '.It', 'has', 'been', 'heretofore', 'noted', 'among', 'the', 'defects', 'of', 'the', 'Confederation', ',', 'that', 'in', 'many', 'of', 'the', 'States', 'it', 'had', 'received', 'no', 'higher', 'sanction', 'than', 'a', 'mere', 'legislative', 'ratification', '.The', 'principle', 'of', 'reciprocality', 'seems', 'to', 'require', 'that', 'its', 'obligation', 'on', 'the', 'other', 'States', 'should', 'be', 'reduced', 'to', 'the', 'same', 'standard', '.']\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:240] subtokens: [CLS] To have required the unanimous rat ##ification of the thirteen States , would have subjected the essential interests of the whole to the cap ##rice or corruption of a single member . It would have marked a want of fore ##sight in the convention , which our own experience would have rendered in ##ex ##cus ##able . Two questions of a very delicate [SEP]\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:241] input_ids: 101 1706 1138 2320 1103 14285 11631 5783 1104 1103 7704 1311 117 1156 1138 13927 1103 6818 4740 1104 1103 2006 1106 1103 6707 10835 1137 8065 1104 170 1423 1420 119 1135 1156 1138 3597 170 1328 1104 24387 18883 1107 1103 6765 117 1134 1412 1319 2541 1156 1138 10029 1107 11708 6697 1895 119 1960 3243 1104 170 1304 10141 102\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-08-10 10:44:31 text_classification_dataset:244] label: 1\n",
      "[NeMo W 2022-08-10 10:44:38 text_classification_dataset:250] Found 502 out of 502 sentences with more than 64 subtokens. Truncated long sentences from the end.\n",
      "[NeMo I 2022-08-10 10:44:38 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-10 10:44:38 data_preprocessing:301] Min: 65 |                  Max: 65 |                  Mean: 65.0 |                  Median: 65.0\n",
      "[NeMo I 2022-08-10 10:44:38 data_preprocessing:307] 75 percentile: 65.00\n",
      "[NeMo I 2022-08-10 10:44:38 data_preprocessing:308] 99 percentile: 65.00\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:120] Read 115 examples from /dli/task/data/federalist_papers_HM/dev_nemo_format.tsv.\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:239] example 0: ['There', 'have', 'been', ',', 'if', 'I', 'may', 'so', 'express', 'it', ',', 'almost', 'as', 'many', 'popular', 'as', 'royal', 'wars', '.The', 'cries', 'of', 'the', 'nation', 'and', 'the', 'importunities', 'of', 'their', 'representatives', 'have', ',', 'upon', 'various', 'occasions', ',', 'dragged', 'their', 'monarchs', 'into', 'war', ',', 'or', 'continued', 'them', 'in', 'it', ',', 'contrary', 'to', 'their', 'inclinations', ',', 'and', 'sometimes', 'contrary', 'to', 'the', 'real', 'interests', 'of', 'the', 'State', '.In', 'that', 'memorable', 'struggle', 'for', 'superiority', 'between', 'the', 'rival', 'houses', 'of', 'AUSTRIA', 'and', 'BOURBON', ',', 'which', 'so', 'long', 'kept', 'Europe', 'in', 'a', 'flame', ',', 'it', 'is', 'well', 'known', 'that', 'the', 'antipathies', 'of', 'the', 'English', 'against', 'the', 'French', ',', 'seconding', 'the', 'ambition', ',', 'or', 'rather', 'the', 'avarice', ',', 'of', 'a', 'favorite', 'leader,10', 'protracted', 'the', 'war', 'beyond', 'the', 'limits', 'marked', 'out', 'by', 'sound', 'policy', ',', 'and', 'for', 'a', 'considerable', 'time', 'in', 'opposition', 'to', 'the', 'views', 'of', 'the', 'court', '.The', 'wars', 'of', 'these', 'two', 'last-mentioned', 'nations', 'have', 'in', 'a', 'great', 'measure', 'grown', 'out', 'of', 'commercial', 'considerations', ',', '--', 'the', 'desire', 'of', 'supplanting', 'and', 'the', 'fear', 'of', 'being', 'supplanted', ',', 'either', 'in', 'particular', 'branches', 'of', 'traffic', 'or', 'in', 'the', 'general', 'advantages', 'of', 'trade', 'and', 'navigation', '.From', 'this', 'summary', 'of', 'what', 'has', 'taken', 'place', 'in', 'other', 'countries', ',', 'whose', 'situations', 'have', 'borne', 'the', 'nearest', 'resemblance', 'to', 'our', 'own', ',', 'what', 'reason', 'can', 'we', 'have', 'to', 'confide', 'in', 'those', 'reveries', 'which', 'would', 'seduce', 'us', 'into', 'an', 'expectation', 'of', 'peace', 'and', 'cordiality', 'between', 'the', 'members', 'of', 'the', 'present', 'confederacy', ',', 'in', 'a', 'state', 'of', 'separation', '?', 'Have', 'we', 'not', 'already', 'seen', 'enough', 'of', 'the', 'fallacy', 'and', 'extravagance', 'of', 'those', 'idle', 'theories', 'which', 'have', 'amused', 'us', 'with', 'promises', 'of', 'an', 'exemption', 'from', 'the', 'imperfections', ',', 'weaknesses', 'and', 'evils', 'incident', 'to', 'society', 'in', 'every', 'shape', '?']\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:240] subtokens: [CLS] There have been , if I may so express it , almost as many popular as royal wars . The cries of the nation and the import ##uni ##ties of their representatives have , upon various occasions , dragged their monarch ##s into war , or continued them in it , contrary to their inclination ##s , and sometimes contrary to the real [SEP]\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:241] input_ids: 101 1247 1138 1151 117 1191 146 1336 1177 6848 1122 117 1593 1112 1242 1927 1112 4276 8755 119 1109 13881 1104 1103 3790 1105 1103 13757 19782 4338 1104 1147 6683 1138 117 1852 1672 6070 117 7509 1147 14390 1116 1154 1594 117 1137 1598 1172 1107 1122 117 11565 1106 1147 24753 1116 117 1105 2121 11565 1106 1103 1842 102\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:239] example 1: ['They', 'would', ',', 'at', 'the', 'same', 'time', ',', 'be', 'necessitated', 'to', 'strengthen', 'the', 'executive', 'arm', 'of', 'government', ',', 'in', 'doing', 'which', 'their', 'constitutions', 'would', 'acquire', 'a', 'progressive', 'direction', 'toward', 'monarchy', '.It', 'is', 'of', 'the', 'nature', 'of', 'war', 'to', 'increase', 'the', 'executive', 'at', 'the', 'expense', 'of', 'the', 'legislative', 'authority', '.The', 'expedients', 'which', 'have', 'been', 'mentioned', 'would', 'soon', 'give', 'the', 'States', 'or', 'confederacies', 'that', 'made', 'use', 'of', 'them', 'a', 'superiority', 'over', 'their', 'neighbors', '.Small', 'states', ',', 'or', 'states', 'of', 'less', 'natural', 'strength', ',', 'under', 'vigorous', 'governments', ',', 'and', 'with', 'the', 'assistance', 'of', 'disciplined', 'armies', ',', 'have', 'often', 'triumphed', 'over', 'large', 'states', ',', 'or', 'states', 'of', 'greater', 'natural', 'strength', ',', 'which', 'have', 'been', 'destitute', 'of', 'these', 'advantages', '.Neither', 'the', 'pride', 'nor', 'the', 'safety', 'of', 'the', 'more', 'important', 'States', 'or', 'confederacies', 'would', 'permit', 'them', 'long', 'to', 'submit', 'to', 'this', 'mortifying', 'and', 'adventitious', 'superiority', '.They', 'would', 'quickly', 'resort', 'to', 'means', 'similar', 'to', 'those', 'by', 'which', 'it', 'had', 'been', 'effected', ',', 'to', 'reinstate', 'themselves', 'in', 'their', 'lost', 'pre-eminence', '.Thus', ',', 'we', 'should', ',', 'in', 'a', 'little', 'time', ',', 'see', 'established', 'in', 'every', 'part', 'of', 'this', 'country', 'the', 'same', 'engines', 'of', 'despotism', 'which', 'have', 'been', 'the', 'scourge', 'of', 'the', 'Old', 'World', '.This', ',', 'at', 'least', ',', 'would', 'be', 'the', 'natural', 'course', 'of', 'things', ';', 'and', 'our', 'reasonings', 'will', 'be', 'the', 'more', 'likely', 'to', 'be', 'just', ',', 'in', 'proportion', 'as', 'they', 'are', 'accommodated', 'to', 'this', 'standard', '.These', 'are', 'not', 'vague', 'inferences', 'drawn', 'from', 'supposed', 'or', 'speculative', 'defects', 'in', 'a', 'Constitution', ',', 'the', 'whole', 'power', 'of', 'which', 'is', 'lodged', 'in', 'the', 'hands', 'of', 'a', 'people', ',', 'or', 'their', 'representatives', 'and', 'delegates', ',', 'but', 'they', 'are', 'solid', 'conclusions', ',', 'drawn', 'from', 'the', 'natural', 'and', 'necessary', 'progress', 'of', 'human', 'affairs', '.']\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:240] subtokens: [CLS] They would , at the same time , be ne ##cess ##itated to strengthen the executive arm of government , in doing which their constitution ##s would acquire a progressive direction toward monarchy . It is of the nature of war to increase the executive at the expense of the legislative authority . The ex ##ped ##ients which have been mentioned would soon [SEP]\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:241] input_ids: 101 1220 1156 117 1120 1103 1269 1159 117 1129 24928 22371 13512 1106 13346 1103 3275 1981 1104 1433 117 1107 1833 1134 1147 7119 1116 1156 9703 170 8706 2447 1755 14358 119 1135 1110 1104 1103 2731 1104 1594 1106 2773 1103 3275 1120 1103 11013 1104 1103 7663 3748 119 1109 4252 3537 24767 1134 1138 1151 3025 1156 1770 102\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-08-10 10:44:38 text_classification_dataset:244] label: 0\n",
      "[NeMo W 2022-08-10 10:44:39 text_classification_dataset:250] Found 115 out of 115 sentences with more than 64 subtokens. Truncated long sentences from the end.\n",
      "[NeMo I 2022-08-10 10:44:39 data_preprocessing:299] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-10 10:44:39 data_preprocessing:301] Min: 65 |                  Max: 65 |                  Mean: 65.0 |                  Median: 65.0\n",
      "[NeMo I 2022-08-10 10:44:39 data_preprocessing:307] 75 percentile: 65.00\n",
      "[NeMo I 2022-08-10 10:44:39 data_preprocessing:308] 99 percentile: 65.00\n",
      "[NeMo I 2022-08-10 10:44:39 text_classification_model:216] Dataloader config or file_path for the test is missing, so no data loader for test is created!\n",
      "[NeMo W 2022-08-10 10:44:39 modelPT:197] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact forit has already been registered.\n",
      "[NeMo W 2022-08-10 10:44:39 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:243: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      self.cfg.update_node(config_path, return_path)\n",
      "    \n",
      "Lock 140037139771792 acquired on /root/.cache/huggingface/transformers/cdd3fa79a58abc10a3331427b8b3d7a13ed15ea2dc5bf6dd67065b007d81f2fb.0749e4f07a7ad43190d183545a30a4899a63bd709586bcc3b30b0f09b025ab3a.lock\n",
      "Downloading: 100%|█████████████████████████| 1.34G/1.34G [00:31<00:00, 43.2MB/s]\n",
      "Lock 140037139771792 released on /root/.cache/huggingface/transformers/cdd3fa79a58abc10a3331427b8b3d7a13ed15ea2dc5bf6dd67065b007d81f2fb.0749e4f07a7ad43190d183545a30a4899a63bd709586bcc3b30b0f09b025ab3a.lock\n",
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertEncoder: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo I 2022-08-10 10:45:20 text_classification_with_bert:118] ===========================================================================================\n",
      "[NeMo I 2022-08-10 10:45:20 text_classification_with_bert:119] Starting training...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-08-10 10:45:20 modelPT:748] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        eps: 1e-08\n",
      "        lr: 2e-05\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2022-08-10 10:45:20 lr_scheduler:617] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f5ceff95be0>\" \n",
      "    will be used during training (effective maximum steps = 160) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 160\n",
      "    )\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "\n",
      "  | Name                  | Type                 | Params\n",
      "---------------------------------------------------------------\n",
      "0 | loss                  | CrossEntropyLoss     | 0     \n",
      "1 | bert_model            | BertEncoder          | 333 M \n",
      "2 | classifier            | SequenceClassifier   | 1.1 M \n",
      "3 | classification_report | ClassificationReport | 0     \n",
      "---------------------------------------------------------------\n",
      "334 M     Trainable params\n",
      "0         Non-trainable params\n",
      "334 M     Total params\n",
      "1,338.524 Total estimated model params size (MB)\n",
      "Epoch 0:  80%|▊| 8/10 [00:02<00:00,  2.76it/s, loss=0.696, v_num=4-31, lr=8.24e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 10/10 [00:03<00:00,  3.23it/s, loss=0.696, v_num=4-31, lr=8.24e\u001b[A[NeMo I 2022-08-10 10:45:26 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 0: 100%|█| 10/10 [00:03<00:00,  3.11it/s, loss=0.696, v_num=4-31, lr=9.41e\n",
      "                                                                                \u001b[AEpoch 0, global step 7: val_loss reached 0.61508 (best 0.61508), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.62-epoch=0.ckpt\" as top 3\n",
      "Epoch 1:  80%|▊| 8/10 [00:02<00:00,  3.26it/s, loss=0.639, v_num=4-31, lr=1.76e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 10/10 [00:02<00:00,  3.71it/s, loss=0.639, v_num=4-31, lr=1.76e\u001b[A[NeMo I 2022-08-10 10:45:45 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 1: 100%|█| 10/10 [00:02<00:00,  3.56it/s, loss=0.639, v_num=4-31, lr=1.88e\n",
      "                                                                                \u001b[AEpoch 1, global step 15: val_loss reached 0.57188 (best 0.57188), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.57-epoch=1.ckpt\" as top 3\n",
      "Epoch 2:  80%|▊| 8/10 [00:02<00:00,  3.34it/s, loss=0.598, v_num=4-31, lr=1.92e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 10/10 [00:02<00:00,  3.83it/s, loss=0.598, v_num=4-31, lr=1.92e\u001b[A[NeMo I 2022-08-10 10:46:13 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 2: 100%|█| 10/10 [00:02<00:00,  3.67it/s, loss=0.598, v_num=4-31, lr=1.9e-\n",
      "                                                                                \u001b[AEpoch 2, global step 23: val_loss reached 0.55075 (best 0.55075), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.55-epoch=2.ckpt\" as top 3\n",
      "Epoch 3:  80%|▊| 8/10 [00:02<00:00,  3.31it/s, loss=0.56, v_num=4-31, lr=1.81e-5\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 10/10 [00:02<00:00,  3.81it/s, loss=0.56, v_num=4-31, lr=1.81e-\u001b[A[NeMo I 2022-08-10 10:46:54 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 3: 100%|█| 10/10 [00:02<00:00,  3.64it/s, loss=0.56, v_num=4-31, lr=1.79e-\n",
      "                                                                                \u001b[AEpoch 3, global step 31: val_loss reached 0.56104 (best 0.55075), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.56-epoch=3.ckpt\" as top 3\n",
      "Epoch 4:  80%|▊| 8/10 [00:02<00:00,  3.27it/s, loss=0.561, v_num=4-31, lr=1.69e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 10/10 [00:02<00:00,  3.76it/s, loss=0.561, v_num=4-31, lr=1.69e\u001b[A[NeMo I 2022-08-10 10:47:24 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 4: 100%|█| 10/10 [00:02<00:00,  3.60it/s, loss=0.561, v_num=4-31, lr=1.68e\n",
      "                                                                                \u001b[AEpoch 4, global step 39: val_loss reached 0.55577 (best 0.55075), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.56-epoch=4.ckpt\" as top 3\n",
      "Epoch 5:  80%|▊| 8/10 [00:02<00:00,  3.26it/s, loss=0.572, v_num=4-31, lr=1.58e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 10/10 [00:02<00:00,  3.74it/s, loss=0.572, v_num=4-31, lr=1.58e\u001b[A[NeMo I 2022-08-10 10:47:55 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 5: 100%|█| 10/10 [00:02<00:00,  3.57it/s, loss=0.572, v_num=4-31, lr=1.57e\n",
      "                                                                                \u001b[AEpoch 5, global step 47: val_loss reached 0.54421 (best 0.54421), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.54-epoch=5.ckpt\" as top 3\n",
      "Epoch 6:  80%|▊| 8/10 [00:02<00:00,  3.28it/s, loss=0.559, v_num=4-31, lr=1.47e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 10/10 [00:02<00:00,  3.74it/s, loss=0.559, v_num=4-31, lr=1.47e\u001b[A[NeMo I 2022-08-10 10:48:22 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             77.39     100.00      87.25         89\n",
      "    label_id: 1                                              0.00       0.00       0.00         26\n",
      "    -------------------\n",
      "    micro avg                                               77.39      77.39      77.39        115\n",
      "    macro avg                                               38.70      50.00      43.63        115\n",
      "    weighted avg                                            59.89      77.39      67.53        115\n",
      "    \n",
      "Epoch 6: 100%|█| 10/10 [00:02<00:00,  3.58it/s, loss=0.559, v_num=4-31, lr=1.46e\n",
      "                                                                                \u001b[AEpoch 6, global step 55: val_loss reached 0.52924 (best 0.52924), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.53-epoch=6.ckpt\" as top 3\n",
      "Epoch 7:  80%|▊| 8/10 [00:02<00:00,  3.21it/s, loss=0.537, v_num=4-31, lr=1.36e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 10/10 [00:02<00:00,  3.66it/s, loss=0.537, v_num=4-31, lr=1.36e\u001b[A[NeMo I 2022-08-10 10:48:50 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             78.76     100.00      88.12         89\n",
      "    label_id: 1                                            100.00       7.69      14.29         26\n",
      "    -------------------\n",
      "    micro avg                                               79.13      79.13      79.13        115\n",
      "    macro avg                                               89.38      53.85      51.20        115\n",
      "    weighted avg                                            83.56      79.13      71.43        115\n",
      "    \n",
      "Epoch 7: 100%|█| 10/10 [00:02<00:00,  3.51it/s, loss=0.537, v_num=4-31, lr=1.35e\n",
      "                                                                                \u001b[AEpoch 7, global step 63: val_loss reached 0.50474 (best 0.50474), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.50-epoch=7.ckpt\" as top 3\n",
      "Epoch 8:  80%|▊| 8/10 [00:02<00:00,  3.26it/s, loss=0.507, v_num=4-31, lr=1.25e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 10/10 [00:02<00:00,  3.73it/s, loss=0.507, v_num=4-31, lr=1.25e\u001b[A[NeMo I 2022-08-10 10:49:21 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             80.37      96.63      87.76         89\n",
      "    label_id: 1                                             62.50      19.23      29.41         26\n",
      "    -------------------\n",
      "    micro avg                                               79.13      79.13      79.13        115\n",
      "    macro avg                                               71.44      57.93      58.58        115\n",
      "    weighted avg                                            76.33      79.13      74.56        115\n",
      "    \n",
      "Epoch 8: 100%|█| 10/10 [00:02<00:00,  3.57it/s, loss=0.507, v_num=4-31, lr=1.24e\n",
      "                                                                                \u001b[AEpoch 8, global step 71: val_loss reached 0.48000 (best 0.48000), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.48-epoch=8.ckpt\" as top 3\n",
      "Epoch 9:  80%|▊| 8/10 [00:02<00:00,  3.26it/s, loss=0.478, v_num=4-31, lr=1.14e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 10/10 [00:02<00:00,  3.74it/s, loss=0.478, v_num=4-31, lr=1.14e\u001b[A[NeMo I 2022-08-10 10:49:51 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             80.00      98.88      88.44         89\n",
      "    label_id: 1                                             80.00      15.38      25.81         26\n",
      "    -------------------\n",
      "    micro avg                                               80.00      80.00      80.00        115\n",
      "    macro avg                                               80.00      57.13      57.12        115\n",
      "    weighted avg                                            80.00      80.00      74.28        115\n",
      "    \n",
      "Epoch 9: 100%|█| 10/10 [00:03<00:00,  3.16it/s, loss=0.478, v_num=4-31, lr=1.13e\n",
      "                                                                                \u001b[AEpoch 9, global step 79: val_loss reached 0.49741 (best 0.48000), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.50-epoch=9.ckpt\" as top 3\n",
      "Epoch 10:  80%|▊| 8/10 [00:02<00:00,  3.23it/s, loss=0.449, v_num=4-31, lr=1.03e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 10/10 [00:02<00:00,  3.70it/s, loss=0.449, v_num=4-31, lr=1.03\u001b[A[NeMo I 2022-08-10 10:50:19 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             86.52      86.52      86.52         89\n",
      "    label_id: 1                                             53.85      53.85      53.85         26\n",
      "    -------------------\n",
      "    micro avg                                               79.13      79.13      79.13        115\n",
      "    macro avg                                               70.18      70.18      70.18        115\n",
      "    weighted avg                                            79.13      79.13      79.13        115\n",
      "    \n",
      "Epoch 10: 100%|█| 10/10 [00:02<00:00,  3.54it/s, loss=0.449, v_num=4-31, lr=1.01\n",
      "                                                                                \u001b[AEpoch 10, global step 87: val_loss reached 0.47385 (best 0.47385), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.47-epoch=10.ckpt\" as top 3\n",
      "Epoch 11:  80%|▊| 8/10 [00:02<00:00,  3.29it/s, loss=0.407, v_num=4-31, lr=9.17e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 10/10 [00:02<00:00,  3.76it/s, loss=0.407, v_num=4-31, lr=9.17\u001b[A[NeMo I 2022-08-10 10:50:48 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             80.56      97.75      88.32         89\n",
      "    label_id: 1                                             71.43      19.23      30.30         26\n",
      "    -------------------\n",
      "    micro avg                                               80.00      80.00      80.00        115\n",
      "    macro avg                                               75.99      58.49      59.31        115\n",
      "    weighted avg                                            78.49      80.00      75.21        115\n",
      "    \n",
      "Epoch 11: 100%|█| 10/10 [00:02<00:00,  3.60it/s, loss=0.407, v_num=4-31, lr=9.03\n",
      "                                                                                \u001b[AEpoch 11, global step 95: val_loss reached 0.48630 (best 0.47385), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.49-epoch=11.ckpt\" as top 3\n",
      "Epoch 12:  80%|▊| 8/10 [00:02<00:00,  3.25it/s, loss=0.379, v_num=4-31, lr=8.06e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 10/10 [00:02<00:00,  3.72it/s, loss=0.379, v_num=4-31, lr=8.06\u001b[A[NeMo I 2022-08-10 10:51:16 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             83.84      93.26      88.30         89\n",
      "    label_id: 1                                             62.50      38.46      47.62         26\n",
      "    -------------------\n",
      "    micro avg                                               80.87      80.87      80.87        115\n",
      "    macro avg                                               73.17      65.86      67.96        115\n",
      "    weighted avg                                            79.01      80.87      79.10        115\n",
      "    \n",
      "Epoch 12: 100%|█| 10/10 [00:02<00:00,  3.56it/s, loss=0.379, v_num=4-31, lr=7.92\n",
      "                                                                                \u001b[AEpoch 12, global step 103: val_loss reached 0.45418 (best 0.45418), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.45-epoch=12.ckpt\" as top 3\n",
      "Epoch 13:  80%|▊| 8/10 [00:02<00:00,  3.24it/s, loss=0.326, v_num=4-31, lr=6.94e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 10/10 [00:02<00:00,  3.73it/s, loss=0.326, v_num=4-31, lr=6.94\u001b[A[NeMo I 2022-08-10 10:51:40 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             82.52      95.51      88.54         89\n",
      "    label_id: 1                                             66.67      30.77      42.11         26\n",
      "    -------------------\n",
      "    micro avg                                               80.87      80.87      80.87        115\n",
      "    macro avg                                               74.60      63.14      65.32        115\n",
      "    weighted avg                                            78.94      80.87      78.04        115\n",
      "    \n",
      "Epoch 13: 100%|█| 10/10 [00:02<00:00,  3.57it/s, loss=0.326, v_num=4-31, lr=6.81\n",
      "                                                                                \u001b[AEpoch 13, global step 111: val_loss reached 0.46952 (best 0.45418), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.47-epoch=13.ckpt\" as top 3\n",
      "Epoch 14:  80%|▊| 8/10 [00:02<00:00,  3.26it/s, loss=0.289, v_num=4-31, lr=5.83e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 10/10 [00:02<00:00,  3.75it/s, loss=0.289, v_num=4-31, lr=5.83\u001b[A[NeMo I 2022-08-10 10:52:05 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             84.00      94.38      88.89         89\n",
      "    label_id: 1                                             66.67      38.46      48.78         26\n",
      "    -------------------\n",
      "    micro avg                                               81.74      81.74      81.74        115\n",
      "    macro avg                                               75.33      66.42      68.83        115\n",
      "    weighted avg                                            80.08      81.74      79.82        115\n",
      "    \n",
      "Epoch 14: 100%|█| 10/10 [00:02<00:00,  3.59it/s, loss=0.289, v_num=4-31, lr=5.69\n",
      "                                                                                \u001b[AEpoch 14, global step 119: val_loss reached 0.46643 (best 0.45418), saving model to \"/dli/task/nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification--val_loss=0.47-epoch=14.ckpt\" as top 3\n",
      "Epoch 15:  80%|▊| 8/10 [00:02<00:00,  3.26it/s, loss=0.245, v_num=4-31, lr=4.72e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 10/10 [00:02<00:00,  3.74it/s, loss=0.245, v_num=4-31, lr=4.72\u001b[A[NeMo I 2022-08-10 10:52:36 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             83.17      94.38      88.42         89\n",
      "    label_id: 1                                             64.29      34.62      45.00         26\n",
      "    -------------------\n",
      "    micro avg                                               80.87      80.87      80.87        115\n",
      "    macro avg                                               73.73      64.50      66.71        115\n",
      "    weighted avg                                            78.90      80.87      78.60        115\n",
      "    \n",
      "Epoch 15: 100%|█| 10/10 [00:02<00:00,  3.57it/s, loss=0.245, v_num=4-31, lr=4.58\n",
      "                                                                                \u001b[AEpoch 15, step 127: val_loss was not in top 3\n",
      "Epoch 16:  80%|▊| 8/10 [00:02<00:00,  3.27it/s, loss=0.212, v_num=4-31, lr=3.61e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 10/10 [00:02<00:00,  3.76it/s, loss=0.212, v_num=4-31, lr=3.61\u001b[A[NeMo I 2022-08-10 10:52:50 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             83.17      94.38      88.42         89\n",
      "    label_id: 1                                             64.29      34.62      45.00         26\n",
      "    -------------------\n",
      "    micro avg                                               80.87      80.87      80.87        115\n",
      "    macro avg                                               73.73      64.50      66.71        115\n",
      "    weighted avg                                            78.90      80.87      78.60        115\n",
      "    \n",
      "Epoch 16: 100%|█| 10/10 [00:02<00:00,  3.60it/s, loss=0.212, v_num=4-31, lr=3.47\n",
      "                                                                                \u001b[AEpoch 16, step 135: val_loss was not in top 3\n",
      "Epoch 17:  80%|▊| 8/10 [00:02<00:00,  3.27it/s, loss=0.193, v_num=4-31, lr=2.5e-\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 10/10 [00:02<00:00,  3.75it/s, loss=0.193, v_num=4-31, lr=2.5e\u001b[A[NeMo I 2022-08-10 10:53:02 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             86.46      93.26      89.73         89\n",
      "    label_id: 1                                             68.42      50.00      57.78         26\n",
      "    -------------------\n",
      "    micro avg                                               83.48      83.48      83.48        115\n",
      "    macro avg                                               77.44      71.63      73.75        115\n",
      "    weighted avg                                            82.38      83.48      82.51        115\n",
      "    \n",
      "Epoch 17: 100%|█| 10/10 [00:02<00:00,  3.59it/s, loss=0.193, v_num=4-31, lr=2.36\n",
      "                                                                                \u001b[AEpoch 17, step 143: val_loss was not in top 3\n",
      "Epoch 18:  80%|▊| 8/10 [00:02<00:00,  3.29it/s, loss=0.172, v_num=4-31, lr=1.39e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 10/10 [00:02<00:00,  3.79it/s, loss=0.172, v_num=4-31, lr=1.39\u001b[A[NeMo I 2022-08-10 10:53:14 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             83.17      94.38      88.42         89\n",
      "    label_id: 1                                             64.29      34.62      45.00         26\n",
      "    -------------------\n",
      "    micro avg                                               80.87      80.87      80.87        115\n",
      "    macro avg                                               73.73      64.50      66.71        115\n",
      "    weighted avg                                            78.90      80.87      78.60        115\n",
      "    \n",
      "Epoch 18: 100%|█| 10/10 [00:02<00:00,  3.63it/s, loss=0.172, v_num=4-31, lr=1.25\n",
      "                                                                                \u001b[AEpoch 18, step 151: val_loss was not in top 3\n",
      "Epoch 19:  80%|▊| 8/10 [00:02<00:00,  3.27it/s, loss=0.171, v_num=4-31, lr=2.78e\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 10/10 [00:02<00:00,  3.76it/s, loss=0.171, v_num=4-31, lr=2.78\u001b[A[NeMo I 2022-08-10 10:53:26 text_classification_model:165] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             83.17      94.38      88.42         89\n",
      "    label_id: 1                                             64.29      34.62      45.00         26\n",
      "    -------------------\n",
      "    micro avg                                               80.87      80.87      80.87        115\n",
      "    macro avg                                               73.73      64.50      66.71        115\n",
      "    weighted avg                                            78.90      80.87      78.60        115\n",
      "    \n",
      "Epoch 19: 100%|█| 10/10 [00:02<00:00,  3.60it/s, loss=0.171, v_num=4-31, lr=1.39\n",
      "                                                                                \u001b[AEpoch 19, step 159: val_loss was not in top 3\n",
      "Epoch 19: 100%|█| 10/10 [00:17<00:00,  1.73s/it, loss=0.171, v_num=4-31, lr=1.39Saving latest checkpoint...\n",
      "Epoch 19: 100%|█| 10/10 [00:31<00:00,  3.13s/it, loss=0.171, v_num=4-31, lr=1.39\n",
      "[NeMo W 2022-08-10 10:53:55 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:308: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      conf.update_node(conf_path, item.path)\n",
      "    \n",
      "[NeMo I 2022-08-10 10:55:09 text_classification_with_bert:121] Training finished!\n",
      "[NeMo I 2022-08-10 10:55:09 text_classification_with_bert:122] ===========================================================================================\n",
      "[NeMo I 2022-08-10 10:56:17 text_classification_with_bert:127] Model is saved into `.nemo` file: text_classification_model.nemo\n",
      "CPU times: user 10.3 s, sys: 3.21 s, total: 13.5 s\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the training script, overriding the config values in the command line\n",
    "TC_DIR = \"/dli/task/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "\n",
    "!python $TC_DIR/text_classification_with_bert.py \\\n",
    "        model.dataset.num_classes=$NUM_CLASSES \\\n",
    "        model.dataset.max_seq_length=$MAX_SEQ_LENGTH \\\n",
    "        model.train_ds.file_path=$PATH_TO_TRAIN_FILE \\\n",
    "        model.validation_ds.file_path=$PATH_TO_VAL_FILE \\\n",
    "        model.infer_samples=[] \\\n",
    "        trainer.max_epochs=$MAX_EPOCHS \\\n",
    "        model.language_model.pretrained_model_name=$PRETRAINED_MODEL_NAME \\\n",
    "        model.train_ds.batch_size=$BATCH_SIZE \\\n",
    "        model.validation_ds.batch_size=$BATCH_SIZE \\\n",
    "        trainer.amp_level=$AMP_LEVEL \\\n",
    "        trainer.precision=$PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to save for assessment- DO NOT CHANGE\n",
    "cmd_log = os.path.join(os.path.dirname(os.path.dirname(get_latest_model())),'cmd-args.log')\n",
    "lightning_logs = os.path.join(os.path.dirname(os.path.dirname(get_latest_model())),'lightning_logs.txt')\n",
    "\n",
    "with open(cmd_log, \"r\") as f:\n",
    "    cmd = f.read()\n",
    "    cmd_list = cmd.split()\n",
    "with open(\"my_assessment/step4.json\", \"w\") as outfile: \n",
    "    json.dump(cmd_list, outfile) \n",
    "    \n",
    "with open(lightning_logs, \"r\") as f:\n",
    "    log = f.readlines()\n",
    "with open(\"my_assessment/step4_lightning.json\", \"w\") as outfile:\n",
    "    json.dump(log, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 5: Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference (graded)\n",
    "Run the inference blocks to see and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-08-10 10:56:41 modelPT:137] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    file_path: /dli/task/data/federalist_papers_HM/train_nemo_format.tsv\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2022-08-10 10:56:41 modelPT:144] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    file_path: /dli/task/data/federalist_papers_HM/dev_nemo_format.tsv\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2022-08-10 10:56:41 modelPT:151] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    file_path: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2022-08-10 10:56:41 modelPT:1198] World size can only be set by PyTorch Lightning Trainer.\n",
      "[NeMo W 2022-08-10 10:56:41 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/core/classes/modelPT.py:243: UserWarning: update_node() is deprecated, use OmegaConf.update(). (Since 2.0)\n",
      "      self.cfg.update_node(config_path, return_path)\n",
      "    \n",
      "[NeMo W 2022-08-10 10:56:41 modelPT:197] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact forit has already been registered.\n",
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-08-10 10:56:54 modelPT:434] Model TextClassificationModel was successfully restored from nemo_experiments/TextClassification/2022-08-10_10-44-31/checkpoints/TextClassification.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-10 10:56:55 text_classification_dataset:250] Found 7 out of 7 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:56 text_classification_dataset:250] Found 4 out of 4 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:56 text_classification_dataset:250] Found 8 out of 8 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:56 text_classification_dataset:250] Found 7 out of 7 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:57 text_classification_dataset:250] Found 9 out of 9 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:57 text_classification_dataset:250] Found 8 out of 8 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:58 text_classification_dataset:250] Found 8 out of 8 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:58 text_classification_dataset:250] Found 6 out of 6 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:56:59 text_classification_dataset:250] Found 9 out of 9 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo W 2022-08-10 10:57:00 text_classification_dataset:250] Found 22 out of 22 sentences with more than 256 subtokens. Truncated long sentences from the end.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0], [1, 0, 0, 0, 1, 1, 1, 1], [1, 1, 0, 0, 0, 0, 1], [0, 1, 1, 1, 1, 1, 1, 0, 0], [0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1], [1, 0, 0, 1, 1, 0], [1, 1, 0, 0, 1, 1, 0, 1, 1], [0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Run inference for assessment -  - DO NOT CHANGE\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "\n",
    "# Instantiate the model by restoring from the latest .nemo checkpoint\n",
    "model = nemo_nlp.models.TextClassificationModel.restore_from(get_latest_model())\n",
    "\n",
    "# Find the latest model path\n",
    "DATA_DIR = '/dli/task/data/federalist_papers_HM'\n",
    "\n",
    "test_files = [\n",
    "    'test49.tsv',\n",
    "    'test50.tsv',\n",
    "    'test51.tsv',\n",
    "    'test52.tsv',\n",
    "    'test53.tsv',\n",
    "    'test54.tsv', \n",
    "    'test55.tsv',\n",
    "    'test56.tsv',\n",
    "    'test57.tsv',\n",
    "    'test62.tsv',\n",
    "]\n",
    "results = []\n",
    "for test_file in test_files:\n",
    "    # get as list and remove header row\n",
    "    filepath = os.path.join(DATA_DIR, test_file)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    del lines[0]\n",
    "    \n",
    "    results.append(model.classifytext(lines, batch_size = 1, max_seq_length = 256))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAMILTON\n",
      "HAMILTON\n",
      "MADISON\n",
      "HAMILTON\n",
      "MADISON\n",
      "MADISON\n",
      "MADISON\n",
      "MADISON\n",
      "MADISON\n",
      "HAMILTON\n"
     ]
    }
   ],
   "source": [
    "# Run to save for assessment- DO NOT CHANGE\n",
    "author = []\n",
    "for result in results:\n",
    "    avg_result = sum(result) / len(result)\n",
    "    if avg_result < 0.5:\n",
    "        author.append(\"HAMILTON\")\n",
    "        print(\"HAMILTON\")\n",
    "    else:\n",
    "        author.append(\"MADISON\")\n",
    "        print(\"MADISON\")\n",
    "        \n",
    "with open(\"my_assessment/step5.json\", \"w\") as outfile: \n",
    "    json.dump(author, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 6: Submit You Assessment\n",
    "How were your results?  According to an earlier [machine learning analysis using support vector machines](http://pages.cs.wisc.edu/~gfung/federalist.pdf), Madison was the most likely true author of all the disputed papers (assuming no collaboration).  It is possible to get the \"all MADISON\" answer using the tools you have.  If you are so inclined, you can keep trying, though **a particular result is *NOT* required to pass the assessment**.\n",
    "\n",
    "If you are satisfied that you have completed the code correctly, and that your training and inference are working correctly, you can submit your project as follows to the autograder:\n",
    "\n",
    "1. Go back to the GPU launch page and click the checkmark to run the assessment:\n",
    "\n",
    "<img src=\"images/assessment_checkmark.png\">\n",
    "\n",
    "2. That's it!  If you passed, you'll receive a pop-up window saying so, and the points will be credited to your progress.  If not, you'll receive feedback in the pop-up window. \n",
    "\n",
    "<img src=\"images/assessment_pass_popup.png\">\n",
    "\n",
    "You can always check your assessment progress in the course progress tab.  Note that partial values for the coding assessment won't be visible here - it shows up as either 0 or 70 points.  Be sure to complete the questions on Transformer and Deployment on the same course page to qualify for your final certificate!\n",
    "\n",
    "<img src=\"images/progress.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"../images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
