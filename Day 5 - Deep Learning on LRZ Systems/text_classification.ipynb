{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1d3bac",
   "metadata": {},
   "source": [
    "### Obtaining the datasets from the Huggingface HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54259b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets\n",
    "\n",
    "\n",
    "existing_datasets = list_datasets()\n",
    "print(\"The HuggingFace contains {} datasets\".format(len(existing_datasets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb457d",
   "metadata": {},
   "source": [
    "We are only interested in the \"emotion\" dataset. This dataset is composed of english tweets labelled with one out of the following six categories: _anger_, _disgust_, _fear_, _joy_, _sadness_, and _suprise_. We can make use of the function `load_dataset()` in order to gather it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e996e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotion_dataset = load_dataset('emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183abf66",
   "metadata": {},
   "source": [
    "The dataset is structured similarly as a Python dictionary (i.e., we can use python dictionary syntax) and provides access to three different split of the data: `train`, `validation`, and `test`. As an example, we can check how many items we have in each of these splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2685fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} elements in the training set'.format(len(emotion_dataset['train'])))\n",
    "print('{} elements in the validation set'.format(len(emotion_dataset['validation'])))\n",
    "print('{} elements in the test set'.format(len(emotion_dataset['test'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e021463",
   "metadata": {},
   "source": [
    "For the sake of curiosity, we could print some of the tweets in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emotion_dataset['train'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af41df",
   "metadata": {},
   "source": [
    "In the next step, we are going to be converting huggingface datasets into pandas structures. Mostly we do this to take advantage of the rich pandas API and visualization features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558956bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "emotion_dataset.set_format(type='pandas')\n",
    "df = emotion_dataset['train'][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ddca3",
   "metadata": {},
   "source": [
    "As seen in the table, the lable is an integer value between 0 and 5. For convenience, we create a function that translate this integer value into the apropiate text for that label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4967c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_int2str(value: int):\n",
    "    return emotion_dataset['train'].features['label'].int2str(value)\n",
    "\n",
    "\n",
    "df['category'] = df['label'].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e30c5",
   "metadata": {},
   "source": [
    "The following graph shows that the data is heavily imbalanced. If we compare the number of tweets labelled as _joy_ and the number of tweets labelled as _surprise_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['category'].value_counts(ascending=True).plot.barh()\n",
    "plt.title('Frequency of tweets within each classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763d42c",
   "metadata": {},
   "source": [
    "How long are tweets? Is there any difference between the lenght of the tweets from different categories. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Words per tweet'] = df['text'].str.split().apply(len)\n",
    "df.boxplot('Words per tweet', by='category', grid=True, showfliers=False,color='black')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ced85",
   "metadata": {},
   "source": [
    "Once finished, if we do not need to make use of the pandas API, the format should be reseted (back to HuggingFace Datasets.) This is achieved with the reset_format function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0577836",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2626f0b",
   "metadata": {},
   "source": [
    "Get a tokenizer trained/tailored to the model we'll use later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e615413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_cpkt = 'distilbert-base-uncased'\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_cpkt)\n",
    "print('The number of tokens in the vocabulary is {}'.format(tokenizer.vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23193a27",
   "metadata": {},
   "source": [
    "We need to define a function that given a batch of sentences, it returns a tokenized version of the sentences in that batch. In the following we define such a function. Observe that this is not a really complex function; instead, it leverages the created tokenizer to convert text to tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369a94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'],padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f39d8",
   "metadata": {},
   "source": [
    "We convert all our dataset to the corresponding list of tokens ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eef6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_encoded = emotion_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emotion_enconded['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6541743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emotion_encoded['train']['input_ids'][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43615750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "device = torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'this is a test'\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf07f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = { k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ca4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48e9223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_state(batch):\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {'hidden_state': last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e785345",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_encoded.set_format('torch', columns=['input_ids','attention_mask','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_hidden = emotion_encoded.map(extract_hidden_state,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_encoded['train'].column_names\n",
    "emotion_hidden['train'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.array(emotion_hidden['train']['hidden_state'])\n",
    "y_train = np.array(emotion_hidden['train']['label'])\n",
    "x_valid = np.array(emotion_hidden['validation']['hidden_state'])\n",
    "y_valid = np.array(emotion_hidden['validation']['label'])\n",
    "x_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54355bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=3000)\n",
    "lr_clf.fit(x_train,y_train)\n",
    "lr_clf.score(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.score(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['This course has arrived to its end. Have a nice weekend!']\n",
    "tokenized_text = tokenizer(text, return_tensors='pt')\n",
    "hidden_state = extract_hidden_state(tokenized_text)\n",
    "prediction = lr_clf.predict(hidden_state['hidden_state'])\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
